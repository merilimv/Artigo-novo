{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates the ability of the DisparateImpactRemover algorithm.\n",
    "The algorithm corrects for imbalanced selection rates between unprivileged and privileged groups at various levels of repair. It follows the guidelines set forth by [1] for training the algorithm and classifier and uses the AdultDataset as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "from aif360.datasets import AdultDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected = 'sex'\n",
    "ad = AdultDataset(protected_attribute_names=[protected],\n",
    "    privileged_classes=[['Male']], categorical_features=[],\n",
    "    features_to_keep=['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']) # OKEY\n",
    "    # just numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = ad.split([16281]) # ? -> não sei\n",
    "train.features = scaler.fit_transform(train.features)\n",
    "test.features = scaler.fit_transform(test.features)\n",
    "\n",
    "index = train.feature_names.index(protected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:13<00:00,  6.67s/it]\n"
     ]
    }
   ],
   "source": [
    "DIs = []\n",
    "SPD = []\n",
    "F1s = []\n",
    "for level in tqdm(np.linspace(0., 1., 11)):\n",
    "    di = DisparateImpactRemover(repair_level=level)\n",
    "    train_repd = di.fit_transform(train)\n",
    "    test_repd = di.fit_transform(test)\n",
    "    \n",
    "    X_tr = np.delete(train_repd.features, index, axis=1)\n",
    "    X_te = np.delete(test_repd.features, index, axis=1)\n",
    "    y_tr = train_repd.labels.ravel()\n",
    "    \n",
    "    lmod = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
    "    lmod.fit(X_tr, y_tr)\n",
    "    \n",
    "    test_repd_pred = test_repd.copy()\n",
    "    test_repd_pred.labels = lmod.predict(X_te)\n",
    "\n",
    "    p = [{protected: 1}]\n",
    "    u = [{protected: 0}]\n",
    "    cm = BinaryLabelDatasetMetric(test_repd_pred, privileged_groups=p, unprivileged_groups=u)\n",
    "    y_true = test_repd.labels.ravel()\n",
    "    y_pred = test_repd_pred.labels.ravel()\n",
    "    DIs.append(cm.disparate_impact())\n",
    "    SPD.append(cm.statistical_parity_difference())\n",
    "    F1s.append(f1_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './/results_DI_remover//adult_results_DI_remover.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      2\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.//results_DI_remover//adult_results_DI_remover.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_name, \u001b[39m'\u001b[39;49m\u001b[39ma\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m files:\n\u001b[1;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m level \u001b[39min\u001b[39;00m (np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.\u001b[39m, \u001b[39m1.\u001b[39m, \u001b[39m11\u001b[39m)):\n\u001b[1;32m      5\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNível de Reparo: \u001b[39m\u001b[39m\"\u001b[39m, level, file \u001b[39m=\u001b[39m files)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './/results_DI_remover//adult_results_DI_remover.csv'"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "file_name = \".//results_DI_remover//adult_results_DI_remover.csv\"\n",
    "with open(file_name, 'a') as files:\n",
    "    for level in (np.linspace(0., 1., 11)):\n",
    "        print(\"Nível de Reparo: \", level, file = files)\n",
    "        print(\"Statistical Parity: \", SPD[i],  file = files)\n",
    "        print(\"F1-Score: \", F1s[i],  file = files)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    References:\n",
    "        .. [1] M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, and\n",
    "           S. Venkatasubramanian, \"Certifying and removing disparate impact.\"\n",
    "           ACM SIGKDD International Conference on Knowledge Discovery and Data\n",
    "           Mining, 2015."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
